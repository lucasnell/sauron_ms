
\renewcommand{\thefigure}{A\arabic{figure}}
\renewcommand{\theequation}{A\arabic{equation}}
\renewcommand{\thetable}{A\arabic{table}}
\setcounter{equation}{0}
\setcounter{figure}{0}
\setcounter{table}{0}


\section*{Appendix A: Matrix derivatives in quantitative genetics equations}


% In this section, we make the following abbreviation in the equations:

% \begin{equation*}
%     \mathbf{\Omega}_{i,t} \equiv N_{i,t} +
%             \sum_{j \ne i}^{n}{ N_{j,t} \, \textrm{e}^{
%             - \mathbf{v}_{j,t}^{\textrm{T}}
%             \mathbf{D} \mathbf{v}_{j,t} } }
% \end{equation*}

\subsection*{Axis change}

The partial derivative of fitness with respect to axes is

\begin{equation*}
\begin{split}
    \frac{ \partial F_{i,t} }{ \partial \mathbf{v}_{i,t} } =
        \exp & \left\{
            r_0
            - f \mathbf{v}_{i,t}^{\textrm{T}} \mathbf{C} \mathbf{v}_{i,t}
            - \alpha_0  \left(
                N_{i,t} + \sum_{j \ne i}^{n}{ N_{j,t} \, \textrm{e}^{
                - \mathbf{v}_{j,t}^{\textrm{T}}
                \mathbf{D} \mathbf{v}_{j,t} } }
            \right) \,
                \textrm{e}^{- \mathbf{v}_{i,t}^{\textrm{T}} \mathbf{v}_{i,t}}
        \right\} \\
        & \left[
            2 \alpha_0 \left(
                N_{i,t} + \sum_{j \ne i}^{n}{ N_{j,t} \, \textrm{e}^{
                - \mathbf{v}_{j,t}^{\textrm{T}}
                \mathbf{D} \mathbf{v}_{j,t} } }
            \right) \,
                \textrm{e}^{- \mathbf{v}_{i,t}^{\textrm{T}} \mathbf{v}_{i,t}} \:
                \mathbf{v}_{i,t}^{\textrm{T}}
            - 2 f \mathbf{v}_{i,t}^{\textrm{T}} \mathbf{C}
        \right]
    \textrm{.}
\end{split}
\end{equation*}


This, combined with equation \ref{eq:axis-change}, means that axes change as follows:

\begin{equation} \label{eq:axes-change-full}
    \mathbf{v}_{i,t+1} = \mathbf{v}_{i,t} + 2 \sigma_i^2
    \left[
        \alpha_0 \, \left(
            N_{i,t} +
            \sum_{j \ne i}^{n}{ N_{j,t} \, \textrm{e}^{
            - \mathbf{v}_{j,t}^{\textrm{T}}
            \mathbf{D} \mathbf{v}_{j,t} } }
        \right) \:
            \textrm{e}^{- \mathbf{v}_{i,t}^{\textrm{T}} \mathbf{v}_{i,t}} \:
            \mathbf{v}_{i,t}^{\textrm{T}}
        - f \, \mathbf{v}_{i,t}^{\textrm{T}} \: \mathbf{C}
    \right]
    \textrm{.}
\end{equation}


\subsection*{Jacobian}

The Jacobian is made up of the following derivatives:

\begin{equation*}
\begin{split}
    \frac{ \partial \, \mathbf{v}_{i,t+1} }{ \partial \, \mathbf{v}_{i,t} } &= 
    \mathbf{I} + 2 ~ \sigma_i^2 ~
        \left[
            \alpha_0 ~ \left(
                N_{i,t} + \sum_{j \ne i}^{n}{ N_{j,t} \, \textrm{e}^{
                - \mathbf{v}_{j,t}^{\textrm{T}}
                \mathbf{D} \mathbf{v}_{j,t} } }
            \right) ~ \textrm{e}^{ - \mathbf{v}_{i,t}^{\textrm{T}} \mathbf{v}_{i,t} }
            \left(
                \mathbf{I} - 2 ~ \mathbf{v}_{i,t} \mathbf{v}_{i,t}^{\textrm{T}}
            \right) -
            f \: \mathbf{C}^{\textrm{T}}
        \right] \\
    \frac{ \partial \: \mathbf{v}_{i,t+1} }{ \partial \: \mathbf{v}_{k,t}} &=
        -4 \; \sigma_i^2 \; \alpha_0 \; N_{k,t} \; \mathbf{v}_{i,t} \;
        \textrm{e}^{
                    - \mathbf{v}_{k,t}^{\textrm{T}} \mathbf{D} \mathbf{v}_{k,t}
                    - \mathbf{v}_{i,t}^{\textrm{T}} \mathbf{v}_{i,t}
                } \;
        \mathbf{v}_{k,t}^{\textrm{T}} \; \mathbf{D} \\
% 
    \frac{ \partial \: \mathbf{v}_{i,t+1} }{ \partial \: N_{i,t} } &=
        2 \; \sigma_i^2 \; \alpha_0 \; \mathbf{v}_{i,t} \;
        \textrm{e}^{ - \mathbf{v}_{i,t}^{\textrm{T}} \mathbf{v}_{i,t} } \\
    \frac{ \partial \: \mathbf{v}_{i,t+1} }{ \partial \: N_{k,t} } &=
        2 \; \sigma_i^2 \; \alpha_0 \; \mathbf{v}_{i,t} \;
        \textrm{e}^{ - \mathbf{v}_{k,t}^{\textrm{T}} \mathbf{D} \mathbf{v}_{k,t}
            - \mathbf{v}_{i,t}^{\textrm{T}} \mathbf{v}_{i,t} } \\
% 
    \frac{ \partial N_{i,t+1} }{ \partial \mathbf{v}_{i,t} } &= 
        2 \, F_{i,t+1} \,  N_{i,t}
        \left[
            \alpha_0 \, \left(
                N_{i,t} + \sum_{j \ne i}^{n}{ N_{j,t} \, \textrm{e}^{
                - \mathbf{v}_{j,t}^{\textrm{T}}
                \mathbf{D} \mathbf{v}_{j,t} } }
            \right) \, \text{e}^{ -\mathbf{v}_{i,t}^{\text{T}}
            \mathbf{v}_{i,t} } \, \mathbf{v}_{i,t}^{\text{T}}
            - f \, \mathbf{v}_{i,t}^{\text{T}} \, \mathbf{C}
        \right] \\
    \frac{ \partial N_{i,t+1} }{ \partial \mathbf{v}_{k,t} } &= 
        2 \, F_{i,t+1} \, N_{i,t} \, N_{k,t} \, \alpha_0 \: 
        \text{e}^{ -\mathbf{v}_{i,t}^{\text{T}} \mathbf{v}_{i,t} -
            \mathbf{v}_{k,t}^{\text{T}} \mathbf{D} \mathbf{v}_{k,t} } \:
        \mathbf{v}_{k,t}^{\text{T}} \, \mathbf{D} \\
% 
    \frac{ \partial N_{i,t+1} }{ \partial N_{i,t} } &= 
        F_{i,t+1}
        \left(
            1 - N_{i,t} \: \alpha_0 \: 
            \text{e}^{ -\mathbf{v}_{i,t}^{\text{T}} \mathbf{v}_{i,t} } 
        \right) \\
    \frac{ \partial N_{i,t+1} }{ \partial N_{k,t} } &= 
        - F_{i,t+1} \: N_{i,t} \: \alpha_0 \: 
        \text{e}^{ -\mathbf{v}_{i,t}^{\text{T}} \mathbf{v}_{i,t} -
            \mathbf{v}_{k,t}^{\text{T}} \mathbf{D} \mathbf{v}_{k,t} } 
    \textrm{.}
\end{split}
\end{equation*}



\subsection*{Keeping axes non-negative}

To keep axes $\ge 0$, we used the ramp function, $R(x)$, which is defined as

\begin{equation*}
    R(x) = \begin{cases}
        x & \text{if}\ x \ge 0 \\
        0 & \text{if}\ x < 0
        \end{cases}
    \text{.}
\end{equation*}


\noindent Its derivative is the Heaviside step function:

\begin{equation*}
\begin{split}
    R'(x) &= H(x) \\
    H(x) &= \begin{cases}
        0 & \text{if}\ x \le 0 \\
        1 & \text{if}\ x > 0
        \end{cases}
    \text{.}
\end{split}
\end{equation*}

% Also see https://see.stanford.edu/materials/lsoftaee261/book-fall-07.pdf
% and https://mathworld.wolfram.com/RampFunction.html

Thus, all axis derivatives of the form $\partial \mathbf{v} / \partial x$
are changed to $H(\mathbf{v}(x)) \: \partial \mathbf{v} / \partial x$ to 
account for axes being non-negative.


